{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "import json\n",
    "# Data Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Extractive Summarizer\n",
    "from models.extractive_summarizer import ExtractiveSummarizer\n",
    "# Encoders for Extractive Summarizer\n",
    "import models.Encoders.Word2Vec as Word2Vecencoder\n",
    "import models.Encoders.TFIDF as TFIDFencoder\n",
    "# Rankers for Extractive Summarizer\n",
    "import models.Rankers.LogisticRegression as LogisticRegressionranker\n",
    "import models.Rankers.LinearRegression as LinearRegressionranker\n",
    "# Decoders for Extractive Summarizer\n",
    "import models.Decoders.PureScore as PureScore\n",
    "import models.Decoders.PureScore as PureRougeSearch\n",
    "import models.Decoders.PureScore as GuidedRougeSearch\n",
    "# Baselines\n",
    "import models.ModelLeadN as LeadN\n",
    "import models.ModelRandom as Random\n",
    "# Evaluator\n",
    "from evaluation.rouge_evaluator import RougeEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "test_PATH = 'data/test.json'\n",
    "train_greedy_sent_PATH = 'data/train.greedy_sent.json'\n",
    "train_PATH = 'data/train.json'\n",
    "validation_PATH = 'data/validation.json'\n",
    "very_small_validation_PATH = 'data/very_small_validation.json'\n",
    "with open(test_PATH, 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "with open(train_greedy_sent_PATH, 'r') as f:\n",
    "    train_greedy_sent_data = json.load(f)\n",
    "with open(train_PATH, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "with open(validation_PATH, 'r') as f:\n",
    "    validation_data = json.load(f)\n",
    "with open(very_small_validation_PATH, 'r') as f:\n",
    "    very_small_validation_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating data shape: 100%|██████████| 10000/10000 [00:00<00:00, 3707835.93it/s]\n",
      "Running extractive summarizer: 100%|█████████▉| 999/1000 [00:00<00:00, 46875.00it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 2741375.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# Table A.1: Random\n",
    "summarizer = Random.ExtractiveSummarizer()\n",
    "pred_data = summarizer.run_extractive_summarization(train_greedy_sent_data , test_data)\n",
    "results = summarizer.eval(RougeEvaluator() , test_data, pred_data)\n",
    "a = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating data shape: 100%|██████████| 10000/10000 [00:00<00:00, 4006403.67it/s]\n",
      "Running extractive summarizer: 100%|█████████▉| 999/1000 [00:00<00:00, 54794.16it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 2644580.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Table A.2: LeadN\n",
    "summarizer = LeadN.ExtractiveSummarizer()\n",
    "pred_data = summarizer.run_extractive_summarization(train_greedy_sent_data , test_data)\n",
    "results = summarizer.eval(RougeEvaluator() , test_data, pred_data)\n",
    "b = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table A.3: TFIDFencoder + LogisticRegressionranker + GuidedRougeSearch\n",
    "num_experiments = 1#0\n",
    "results = None\n",
    "for i in range(num_experiments):\n",
    "    summarizer = ExtractiveSummarizer(encoder=TFIDFencoder, ranker=LogisticRegressionranker, decoder=GuidedRougeSearch)\n",
    "    pred_data = summarizer.run_extractive_summarization(train_greedy_sent_data , test_data)\n",
    "    try:\n",
    "        results += summarizer.eval(RougeEvaluator() , test_data, pred_data) / num_experiments\n",
    "    except:\n",
    "        results = summarizer.eval(RougeEvaluator() , test_data, pred_data) / num_experiments\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table C.1: TFIDFencoder + LogisticRegressionranker + PureScore\n",
    "summarizer = ExtractiveSummarizer(encoder=TFIDFencoder, ranker=LogisticRegressionranker, decoder=PureScore)\n",
    "pred_data = summarizer.run_extractive_summarization(train_greedy_sent_data , test_data)\n",
    "results = summarizer.eval(RougeEvaluator() , test_data, pred_data)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table C.2: TFIDFencoder + LinearRegression + GuidedRougeSearch\n",
    "summarizer = ExtractiveSummarizer(encoder=TFIDFencoder, ranker=LinearRegressionranker, decoder=GuidedRougeSearch)\n",
    "pred_data = summarizer.run_extractive_summarization(train_greedy_sent_data , test_data)\n",
    "results = summarizer.eval(RougeEvaluator() , test_data, pred_data)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table C.3: Word2Vecencoder + LogisticRegressionranker + GuidedRougeSearch\n",
    "summarizer = ExtractiveSummarizer(encoder=Word2Vecencoder, ranker=LogisticRegressionranker, decoder=GuidedRougeSearch)\n",
    "pred_data = summarizer.run_extractive_summarization(train_greedy_sent_data , test_data)\n",
    "results = summarizer.eval(RougeEvaluator() , test_data, pred_data)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table C.4: Word2Vecencoder + LinearRegression + GuidedRougeSearch\n",
    "summarizer = ExtractiveSummarizer(encoder=Word2Vecencoder, ranker=LinearRegressionranker, decoder=GuidedRougeSearch)\n",
    "pred_data = summarizer.run_extractive_summarization(train_greedy_sent_data , test_data)\n",
    "results = summarizer.eval(RougeEvaluator() , test_data, pred_data)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating data shape: 100%|██████████| 10000/10000 [00:00<00:00, 3745248.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Word Vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running X_2_VectorList: 100%|██████████| 10000/10000 [00:15<00:00, 625.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running extractive summarizer: 100%|█████████▉| 999/1000 [00:02<00:00, 360.24it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 183381.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Table C.5: Word2Vecencoder + LinearRegression + PureScore\n",
    "summarizer = ExtractiveSummarizer(encoder=Word2Vecencoder, ranker=LinearRegressionranker, decoder=PureScore)\n",
    "pred_data = summarizer.run_extractive_summarization(train_greedy_sent_data , test_data)\n",
    "results = summarizer.eval(RougeEvaluator() , test_data, pred_data)\n",
    "c = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Random</th>\n",
       "      <th>rouge-1</th>\n",
       "      <td>0.294</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge-2</th>\n",
       "      <td>0.077</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge-4</th>\n",
       "      <td>0.023</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge-l</th>\n",
       "      <td>0.243</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">LeadN</th>\n",
       "      <th>rouge-1</th>\n",
       "      <td>0.454</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge-2</th>\n",
       "      <td>0.185</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge-4</th>\n",
       "      <td>0.067</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge-l</th>\n",
       "      <td>0.380</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Word2Vecencoder + LinearRegression</th>\n",
       "      <th>rouge-1</th>\n",
       "      <td>0.426</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge-2</th>\n",
       "      <td>0.152</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge-4</th>\n",
       "      <td>0.051</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge-l</th>\n",
       "      <td>0.355</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Recall  Precision  F1-score\n",
       "Random                             rouge-1   0.294      0.264     0.278\n",
       "                                   rouge-2   0.077      0.068     0.072\n",
       "                                   rouge-4   0.023      0.021     0.022\n",
       "                                   rouge-l   0.243      0.221     0.231\n",
       "LeadN                              rouge-1   0.454      0.321     0.376\n",
       "                                   rouge-2   0.185      0.130     0.153\n",
       "                                   rouge-4   0.067      0.048     0.056\n",
       "                                   rouge-l   0.380      0.269     0.315\n",
       "Word2Vecencoder + LinearRegression rouge-1   0.426      0.274     0.334\n",
       "                                   rouge-2   0.152      0.099     0.120\n",
       "                                   rouge-4   0.051      0.035     0.041\n",
       "                                   rouge-l   0.355      0.230     0.279"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat({'Random': a, 'LeadN':b, 'Word2Vecencoder + LinearRegression':c}).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table C.6: PureRougeSearch - \n",
    "summarizer = ExtractiveSummarizer(encoder=TFIDFencoder, ranker=LinearRegressionranker, decoder=PureRougeSearch)\n",
    "pred_data = summarizer.run_extractive_summarization(train_greedy_sent_data , test_data)\n",
    "results = summarizer.eval(RougeEvaluator() , test_data, pred_data)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
